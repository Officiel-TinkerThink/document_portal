{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0494af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all_ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ce4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8608be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5c8a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b5088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatGroq(model=\"qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e9e0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so the user is asking, \"What is the capital of France?\" Let me start by recalling what I know about France. France is a country in Western Europe, and like many countries, it has a capital city. From what I remember, the capital of France is Paris. But wait, let me make sure I\\'m not confusing it with another country. For example, I know that the capital of the UK is London, Germany\\'s is Berlin, Spain\\'s is Madrid. France\\'s capital is definitely Paris. I think Paris is also a major city in France, known for the Eiffel Tower, the Louvre, and other landmarks. But just to be thorough, maybe I should double-check if there\\'s any other city that could be considered a capital. Sometimes countries have other important cities, like administrative capitals or unofficial capitals, but in France\\'s case, Paris is the official capital. I don\\'t think there\\'s any other city that holds that title. So, the answer should be Paris. Let me confirm with some basic facts: the government is based in Paris, the president works from the Élysée Palace there, and the city is the cultural and economic hub. Yeah, I\\'m pretty confident that Paris is the correct answer here. No need to overcomplicate it. The user probably just wants a straightforward answer without any confusion. So, the capital of France is Paris.\\n</think>\\n\\nThe capital of France is **Paris**. It is the political, economic, and cultural center of the country, home to iconic landmarks such as the Eiffel Tower, the Louvre Museum, and the Notre-Dame Cathedral. Paris has served as the capital since 1549 and remains a major global city. \\n\\n**Answer:** Paris.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What is the capital of france?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a98f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "115012d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f2855c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.01596272550523281,\n",
       " 0.024127934128046036,\n",
       " -0.024884698912501335,\n",
       " -0.047665104269981384,\n",
       " 0.015882620587944984,\n",
       " 0.02082662098109722,\n",
       " 0.015962805598974228,\n",
       " -0.011674212291836739,\n",
       " -0.05381821095943451,\n",
       " 0.07729942351579666,\n",
       " -0.025974301621317863,\n",
       " -0.059751562774181366,\n",
       " 0.02774067409336567,\n",
       " 0.04595344513654709,\n",
       " -0.03897486999630928,\n",
       " -0.05059661716222763,\n",
       " 0.0017077191732823849,\n",
       " 0.019309965893626213,\n",
       " -0.1275205761194229,\n",
       " 0.02953471429646015,\n",
       " 0.03668486326932907,\n",
       " -0.019635213539004326,\n",
       " 0.03356068208813667,\n",
       " -0.005102636758238077,\n",
       " 0.032824866473674774,\n",
       " -0.023588696494698524,\n",
       " -0.010589244775474072,\n",
       " 0.020889902487397194,\n",
       " -0.012791345827281475,\n",
       " -0.005309789441525936,\n",
       " 0.02341156080365181,\n",
       " 0.08677323162555695,\n",
       " -0.013178846798837185,\n",
       " -0.06579287350177765,\n",
       " -0.0035997263621538877,\n",
       " -0.00029272589017637074,\n",
       " -0.012163406237959862,\n",
       " 0.026200320571660995,\n",
       " 0.05586111173033714,\n",
       " -0.030531514436006546,\n",
       " -0.04869668930768967,\n",
       " 0.04467296972870827,\n",
       " -0.0021678053308278322,\n",
       " 0.025752756744623184,\n",
       " -0.03563884273171425,\n",
       " -0.02922186627984047,\n",
       " 0.02928924933075905,\n",
       " 0.0601607970893383,\n",
       " -0.0023320994805544615,\n",
       " 0.011702335439622402,\n",
       " 0.0038959993980824947,\n",
       " 0.01466058474034071,\n",
       " -0.0715053603053093,\n",
       " 0.018814099952578545,\n",
       " -0.010276283137500286,\n",
       " -0.005761431530117989,\n",
       " -0.036028824746608734,\n",
       " -0.008495213463902473,\n",
       " 0.06560496985912323,\n",
       " 0.02465587668120861,\n",
       " 0.030258890241384506,\n",
       " 0.028867103159427643,\n",
       " -0.00011565360910026357,\n",
       " 0.02029508166015148,\n",
       " 0.02956826612353325,\n",
       " -0.01966594159603119,\n",
       " -0.0015340305399149656,\n",
       " -0.015292669646441936,\n",
       " -0.010114713571965694,\n",
       " 0.0629536360502243,\n",
       " -0.04569729045033455,\n",
       " 0.07363040745258331,\n",
       " -0.008010761812329292,\n",
       " 0.06520552933216095,\n",
       " -0.018664060160517693,\n",
       " -0.03868398815393448,\n",
       " 0.017543477937579155,\n",
       " -0.05587555095553398,\n",
       " 0.005037933588027954,\n",
       " 0.042954474687576294,\n",
       " -0.0302091334015131,\n",
       " 0.01711495965719223,\n",
       " 0.07823215425014496,\n",
       " 0.066586934030056,\n",
       " -0.0004910434363409877,\n",
       " 0.022750670090317726,\n",
       " 0.006314563564956188,\n",
       " -0.025905214250087738,\n",
       " -0.027560805901885033,\n",
       " -0.03542819246649742,\n",
       " 0.048929888755083084,\n",
       " 0.024888601154088974,\n",
       " -0.03336251527070999,\n",
       " -0.0011026517022401094,\n",
       " 0.06247762590646744,\n",
       " -0.020418766885995865,\n",
       " -0.07869640737771988,\n",
       " -0.10645400732755661,\n",
       " 0.09195823967456818,\n",
       " 0.006735621951520443,\n",
       " -0.0030848802998661995,\n",
       " 0.0204879492521286,\n",
       " -0.028215749189257622,\n",
       " -0.04945649206638336,\n",
       " 0.014937806874513626,\n",
       " 0.0617445632815361,\n",
       " 0.012314978986978531,\n",
       " -0.06418222188949585,\n",
       " -0.0313781313598156,\n",
       " 0.001139173749834299,\n",
       " -0.0024314855691045523,\n",
       " -0.02619570679962635,\n",
       " 0.03302318975329399,\n",
       " -0.03812519460916519,\n",
       " 0.0038771929685026407,\n",
       " -0.007954363711178303,\n",
       " -0.030563196167349815,\n",
       " -0.004512977786362171,\n",
       " -0.034157637506723404,\n",
       " 0.073418989777565,\n",
       " -0.04781952500343323,\n",
       " 0.023326274007558823,\n",
       " -0.00662418594583869,\n",
       " 0.06852427124977112,\n",
       " 0.06219123303890228,\n",
       " 0.009691765531897545,\n",
       " -0.022520245984196663,\n",
       " -0.009043723344802856,\n",
       " -0.022794967517256737,\n",
       " -0.08625742793083191,\n",
       " 0.08657418191432953,\n",
       " -0.013365431688725948,\n",
       " 0.026696335524320602,\n",
       " 0.008371949195861816,\n",
       " -0.04136688634753227,\n",
       " -0.016486678272485733,\n",
       " 0.03840520605444908,\n",
       " -0.018775563687086105,\n",
       " 0.004394540097564459,\n",
       " 0.02389838732779026,\n",
       " -0.01752975396811962,\n",
       " -0.027096865698695183,\n",
       " -0.042877063155174255,\n",
       " 0.007984891533851624,\n",
       " 0.03159954398870468,\n",
       " -0.01737128384411335,\n",
       " -0.03330020606517792,\n",
       " 0.006336982361972332,\n",
       " -0.031066754832863808,\n",
       " -0.0025436710566282272,\n",
       " -0.016962867230176926,\n",
       " -0.025692841038107872,\n",
       " 0.05022353678941727,\n",
       " -0.028776468709111214,\n",
       " -0.021441107615828514,\n",
       " 0.017185881733894348,\n",
       " 0.03851472586393356,\n",
       " -0.020335746929049492,\n",
       " 0.03791952133178711,\n",
       " -0.010972937569022179,\n",
       " 0.018300576135516167,\n",
       " -0.03212187811732292,\n",
       " -0.039821624755859375,\n",
       " 0.019817650318145752,\n",
       " -0.02629290521144867,\n",
       " 0.006331372074782848,\n",
       " 0.027066057547926903,\n",
       " -0.05222456529736519,\n",
       " -0.021136481314897537,\n",
       " -0.03581755980849266,\n",
       " -0.030284928157925606,\n",
       " -0.03259321302175522,\n",
       " -0.008960219100117683,\n",
       " -0.12972097098827362,\n",
       " -0.0008815850596874952,\n",
       " -0.01672379858791828,\n",
       " -0.03283119574189186,\n",
       " -0.006947287358343601,\n",
       " -0.01847183145582676,\n",
       " -0.032290007919073105,\n",
       " 0.08698901534080505,\n",
       " 0.023684410378336906,\n",
       " -0.0031585143879055977,\n",
       " -0.0672072321176529,\n",
       " 0.0272816251963377,\n",
       " 0.019333243370056152,\n",
       " -0.01940876990556717,\n",
       " 0.03975200280547142,\n",
       " 0.04072387516498566,\n",
       " -0.00011655723938019946,\n",
       " -0.057771388441324234,\n",
       " -0.00031717264209873974,\n",
       " 0.024558167904615402,\n",
       " 0.05260750278830528,\n",
       " 0.01850971207022667,\n",
       " -0.02057064138352871,\n",
       " -0.008900088258087635,\n",
       " -0.06593099981546402,\n",
       " -0.026758814230561256,\n",
       " -0.047985296696424484,\n",
       " 0.03898129612207413,\n",
       " -0.022166596725583076,\n",
       " 0.035107530653476715,\n",
       " 0.020010124891996384,\n",
       " -0.02167617343366146,\n",
       " 0.021525615826249123,\n",
       " -0.039866842329502106,\n",
       " -0.04050741717219353,\n",
       " -0.0419929064810276,\n",
       " 0.039675723761320114,\n",
       " -0.0353643037378788,\n",
       " -0.02689480595290661,\n",
       " -0.024875281378626823,\n",
       " -0.04482885077595711,\n",
       " 0.019451214000582695,\n",
       " -0.04285315051674843,\n",
       " 0.07526195794343948,\n",
       " -0.03390185534954071,\n",
       " 0.10165262222290039,\n",
       " -0.04829885810613632,\n",
       " 0.028729230165481567,\n",
       " -0.0018085568444803357,\n",
       " 0.09902776032686234,\n",
       " 0.04967767745256424,\n",
       " 0.02857149764895439,\n",
       " 0.008747872896492481,\n",
       " 0.005044213496148586,\n",
       " 0.010931005701422691,\n",
       " -0.030153898522257805,\n",
       " -0.031046539545059204,\n",
       " 0.018968677148222923,\n",
       " 0.006635233294218779,\n",
       " 0.0041863881051540375,\n",
       " 0.0184189360588789,\n",
       " -0.029654867947101593,\n",
       " -0.00728062866255641,\n",
       " -0.02773929201066494,\n",
       " -0.012522944249212742,\n",
       " -0.030265161767601967,\n",
       " -0.009240813553333282,\n",
       " 0.0025086908135563135,\n",
       " -0.054927513003349304,\n",
       " -0.0060244775377213955,\n",
       " 0.004267530515789986,\n",
       " 0.0151634830981493,\n",
       " 0.03100966475903988,\n",
       " 0.052696578204631805,\n",
       " 0.038965389132499695,\n",
       " -0.02997894026339054,\n",
       " -0.013646988198161125,\n",
       " -0.032005246728658676,\n",
       " 0.007082377094775438,\n",
       " -0.03279908373951912,\n",
       " -0.051547396928071976,\n",
       " -0.0847427099943161,\n",
       " -0.06050846725702286,\n",
       " -0.0012364182621240616,\n",
       " -0.009736089035868645,\n",
       " 0.01777864806354046,\n",
       " -0.00812861043959856,\n",
       " 0.02897152304649353,\n",
       " 0.021951284259557724,\n",
       " -0.04846714437007904,\n",
       " -0.04605086147785187,\n",
       " -0.07441036403179169,\n",
       " -0.02584298886358738,\n",
       " -0.04445572569966316,\n",
       " -0.05579140782356262,\n",
       " 0.013697938062250614,\n",
       " -0.020573284476995468,\n",
       " -0.0032278995495289564,\n",
       " -0.035361453890800476,\n",
       " -0.059344541281461716,\n",
       " 0.00745242927223444,\n",
       " -0.003817823948338628,\n",
       " 0.025016408413648605,\n",
       " -0.0156968142837286,\n",
       " 0.006103699095547199,\n",
       " -0.02322736382484436,\n",
       " -0.05889114737510681,\n",
       " 0.007910520769655704,\n",
       " 0.030986500903964043,\n",
       " -0.015481604263186455,\n",
       " -0.015152523294091225,\n",
       " 0.009164842776954174,\n",
       " 0.00032895049662329257,\n",
       " -0.01366716530174017,\n",
       " 0.0394272617995739,\n",
       " -0.01831471547484398,\n",
       " -0.010642064735293388,\n",
       " 0.02610921300947666,\n",
       " 0.07610476016998291,\n",
       " 0.031474631279706955,\n",
       " -0.054582905024290085,\n",
       " 0.04122545197606087,\n",
       " 0.03595518320798874,\n",
       " 0.012031040154397488,\n",
       " 0.030137477442622185,\n",
       " -0.012752514332532883,\n",
       " 0.018501849845051765,\n",
       " 0.013759306631982327,\n",
       " 0.0407741405069828,\n",
       " -0.020124543458223343,\n",
       " 0.006298442371189594,\n",
       " 0.008692150004208088,\n",
       " -0.01792701706290245,\n",
       " -0.036470927298069,\n",
       " -0.04651973396539688,\n",
       " -0.04453543573617935,\n",
       " 0.03611874207854271,\n",
       " -0.045065756887197495,\n",
       " 0.0681009292602539,\n",
       " -0.023691361770033836,\n",
       " -0.04982630908489227,\n",
       " -0.020593615248799324,\n",
       " -0.03139054402709007,\n",
       " -0.17440927028656006,\n",
       " 0.0024415012449026108,\n",
       " 0.012396600097417831,\n",
       " -0.029697636142373085,\n",
       " 0.018744302913546562,\n",
       " 0.04882261902093887,\n",
       " 0.01751779392361641,\n",
       " 0.010380261577665806,\n",
       " 0.016298526898026466,\n",
       " -0.017149338498711586,\n",
       " 0.01688712276518345,\n",
       " -0.027514969930052757,\n",
       " 0.017675533890724182,\n",
       " 0.03130054473876953,\n",
       " 0.0037475444842129946,\n",
       " 0.004078024998307228,\n",
       " -0.01657329872250557,\n",
       " -0.030352532863616943,\n",
       " -0.0036953624803572893,\n",
       " 0.048352476209402084,\n",
       " -0.044743072241544724,\n",
       " 0.048038821667432785,\n",
       " 0.037638042122125626,\n",
       " 0.042179275304079056,\n",
       " 0.03635011240839958,\n",
       " -0.006517705973237753,\n",
       " 0.005947959143668413,\n",
       " 0.06089397892355919,\n",
       " -0.010861082002520561,\n",
       " -0.08057576417922974,\n",
       " 0.014743344858288765,\n",
       " 0.012205391190946102,\n",
       " 0.051466431468725204,\n",
       " -0.005233802832663059,\n",
       " 0.004373583011329174,\n",
       " 0.06566765159368515,\n",
       " -0.010239007882773876,\n",
       " -0.05180013179779053,\n",
       " -0.003702906658872962,\n",
       " -0.015191434882581234,\n",
       " 0.038237277418375015,\n",
       " -0.017858659848570824,\n",
       " 0.016414683312177658,\n",
       " -0.01855175755918026,\n",
       " -0.009672364220023155,\n",
       " -0.017541637644171715,\n",
       " -0.0350433774292469,\n",
       " -0.01379517000168562,\n",
       " 0.0023933714255690575,\n",
       " -0.008316265419125557,\n",
       " 0.0024885127786546946,\n",
       " 0.019723115488886833,\n",
       " -0.0005869566230103374,\n",
       " -0.004585375543683767,\n",
       " 0.02690996043384075,\n",
       " 0.024151163175702095,\n",
       " -0.03511000797152519,\n",
       " 0.0387193001806736,\n",
       " 0.018793795257806778,\n",
       " -0.006073402240872383,\n",
       " -0.07383308559656143,\n",
       " 0.06249340996146202,\n",
       " 0.014783545397222042,\n",
       " 0.03935275226831436,\n",
       " -0.014588143676519394,\n",
       " -0.03929490968585014,\n",
       " -0.05477755144238472,\n",
       " -0.0027357665821909904,\n",
       " -0.014788778498768806,\n",
       " 0.07075594365596771,\n",
       " -0.05115022882819176,\n",
       " 0.024056335911154747,\n",
       " -0.047349583357572556,\n",
       " -0.02085491269826889,\n",
       " -0.0010208608582615852,\n",
       " 0.07398142665624619,\n",
       " 0.02263873815536499,\n",
       " 0.004853892605751753,\n",
       " -0.041109099984169006,\n",
       " 0.05873304232954979,\n",
       " -0.010252377949655056,\n",
       " 0.022695885971188545,\n",
       " 0.007226293906569481,\n",
       " -0.001505959895439446,\n",
       " -0.002066581277176738,\n",
       " -0.036948494613170624,\n",
       " 0.058633267879486084,\n",
       " -0.06832720339298248,\n",
       " -0.017233682796359062,\n",
       " -0.011053760536015034,\n",
       " 0.006482122931629419,\n",
       " 0.011045999825000763,\n",
       " -0.038270387798547745,\n",
       " 0.0039495197124779224,\n",
       " -0.007455740123987198,\n",
       " -0.059752870351076126,\n",
       " -0.04937241971492767,\n",
       " -0.013251068070530891,\n",
       " -0.045350365340709686,\n",
       " -0.0030549527145922184,\n",
       " 0.007084978744387627,\n",
       " -0.023166293278336525,\n",
       " 0.03261382505297661,\n",
       " 0.037893977016210556,\n",
       " -0.026108911260962486,\n",
       " -0.04149244353175163,\n",
       " 0.004567994270473719,\n",
       " 0.023497063666582108,\n",
       " 0.03062397800385952,\n",
       " -0.05811247602105141,\n",
       " -0.017794890329241753,\n",
       " -0.003515965770930052,\n",
       " -0.013313175179064274,\n",
       " 0.015895308926701546,\n",
       " 0.005251286551356316,\n",
       " 0.05164721980690956,\n",
       " -0.006049588788300753,\n",
       " 0.1104298084974289,\n",
       " 0.023374682292342186,\n",
       " 0.008570622652769089,\n",
       " 0.013217165134847164,\n",
       " -0.003478993196040392,\n",
       " 0.015535419806838036,\n",
       " -0.007561422418802977,\n",
       " 0.02032848447561264,\n",
       " 0.02501477673649788,\n",
       " 0.024016473442316055,\n",
       " 0.04393704980611801,\n",
       " -0.034153349697589874,\n",
       " 0.05196814984083176,\n",
       " 0.0446912981569767,\n",
       " 0.0280435923486948,\n",
       " -0.018600083887577057,\n",
       " -0.06498619168996811,\n",
       " 0.00920077320188284,\n",
       " -0.05905173718929291,\n",
       " -0.030041459947824478,\n",
       " 0.012229700572788715,\n",
       " -0.019802523776888847,\n",
       " -0.016468897461891174,\n",
       " -0.014859928749501705,\n",
       " -0.023262597620487213,\n",
       " -0.025879962369799614,\n",
       " 0.03036121279001236,\n",
       " -0.015756670385599136,\n",
       " -0.0115385502576828,\n",
       " 0.07972420006990433,\n",
       " 0.028406597673892975,\n",
       " -0.026970965787768364,\n",
       " -0.040142972022295,\n",
       " 0.042853374034166336,\n",
       " -0.021938594058156013,\n",
       " -0.08451174944639206,\n",
       " 0.012417991645634174,\n",
       " 0.05124061554670334,\n",
       " 0.011531411670148373,\n",
       " 0.03343723341822624,\n",
       " -0.016817018389701843,\n",
       " -0.008111190982162952,\n",
       " 0.030734052881598473,\n",
       " 0.05035611614584923,\n",
       " 0.011324653401970863,\n",
       " -0.06596991419792175,\n",
       " -0.04100557789206505,\n",
       " -0.03181231766939163,\n",
       " 0.013575374148786068,\n",
       " 0.0019028407987207174,\n",
       " 0.003422376001253724,\n",
       " 0.02594033256173134,\n",
       " 0.0037788841873407364,\n",
       " -0.04437951743602753,\n",
       " 0.0014083011774346232,\n",
       " -0.025092000141739845,\n",
       " 0.03853374719619751,\n",
       " -0.03168920800089836,\n",
       " 0.015733005478978157,\n",
       " -0.008857781067490578,\n",
       " -0.05652042105793953,\n",
       " 0.026131203398108482,\n",
       " -0.02023552544414997,\n",
       " 0.06653905659914017,\n",
       " -0.03253006562590599,\n",
       " 0.007775411009788513,\n",
       " 0.04434812068939209,\n",
       " 0.08253428339958191,\n",
       " 0.0197819285094738,\n",
       " -0.03355175629258156,\n",
       " -0.05253905802965164,\n",
       " -0.036992397159338,\n",
       " 0.05286603793501854,\n",
       " -0.03237687796354294,\n",
       " -0.0354478619992733,\n",
       " 0.05743216350674629,\n",
       " 0.014102389104664326,\n",
       " -0.01067299209535122,\n",
       " -0.012285765260457993,\n",
       " 0.023934656754136086,\n",
       " 0.03610503301024437,\n",
       " 0.036337874829769135,\n",
       " 0.013574761338531971,\n",
       " -0.04593665525317192,\n",
       " -0.017092030495405197,\n",
       " -0.04455810785293579,\n",
       " -0.008828038349747658,\n",
       " -0.02037459798157215,\n",
       " 0.01793300174176693,\n",
       " 0.06278205662965775,\n",
       " -0.016667963936924934,\n",
       " 0.038892962038517,\n",
       " -0.04657474160194397,\n",
       " 0.02176547609269619,\n",
       " 0.03735845163464546,\n",
       " 0.003235999494791031,\n",
       " -0.027893517166376114,\n",
       " -0.06951767206192017,\n",
       " 0.033037178218364716,\n",
       " 0.012999133206903934,\n",
       " 0.038599055260419846,\n",
       " 0.02287457138299942,\n",
       " 0.013157260604202747,\n",
       " -0.004674714989960194,\n",
       " 0.036996111273765564,\n",
       " -0.007127170916646719,\n",
       " 0.007607638835906982,\n",
       " -0.008574021980166435,\n",
       " -0.02138541080057621,\n",
       " 0.0063781412318348885,\n",
       " 0.08617870509624481,\n",
       " 0.03168762847781181,\n",
       " -0.014385142363607883,\n",
       " -0.005685781128704548,\n",
       " 0.016816623508930206,\n",
       " -0.018328864127397537,\n",
       " 0.05749482661485672,\n",
       " 0.02573237754404545,\n",
       " -0.009462258778512478,\n",
       " -0.04813360795378685,\n",
       " -0.021241119131445885,\n",
       " -0.026463227346539497,\n",
       " -0.03739644214510918,\n",
       " 0.0033009278122335672,\n",
       " -0.025190601125359535,\n",
       " -0.0465678907930851,\n",
       " -0.030599409714341164,\n",
       " -0.023717118427157402,\n",
       " -0.0032539325766265392,\n",
       " -0.002347237430512905,\n",
       " -0.02431640587747097,\n",
       " -0.03388150781393051,\n",
       " 0.012027469463646412,\n",
       " -0.0075181275606155396,\n",
       " 0.038811855018138885,\n",
       " -0.025055736303329468,\n",
       " 0.02268548496067524,\n",
       " -0.014529351145029068,\n",
       " 0.003073094878345728,\n",
       " -0.03248006850481033,\n",
       " -0.0339730940759182,\n",
       " 0.01028562244027853,\n",
       " 0.025598136708140373,\n",
       " -0.030923154205083847,\n",
       " 0.03230664134025574,\n",
       " 0.02174466662108898,\n",
       " -0.022975314408540726,\n",
       " -0.04538175091147423,\n",
       " -0.01134067215025425,\n",
       " 0.02416541986167431,\n",
       " -0.022060146555304527,\n",
       " 0.04151264578104019,\n",
       " -0.013194245286285877,\n",
       " 0.009412434883415699,\n",
       " -0.005056455265730619,\n",
       " 0.026985198259353638,\n",
       " 0.02420150861144066,\n",
       " 0.03200994431972504,\n",
       " 0.020130859687924385,\n",
       " -0.007446623407304287,\n",
       " -0.06008189544081688,\n",
       " -0.027727054432034492,\n",
       " -0.014139208942651749,\n",
       " -0.05478806048631668,\n",
       " 0.06002374365925789,\n",
       " 0.03602929040789604,\n",
       " -0.004168453626334667,\n",
       " -0.010479592718183994,\n",
       " -0.005727814510464668,\n",
       " -0.03356730565428734,\n",
       " 0.0009078866569325328,\n",
       " -0.015431328676640987,\n",
       " -0.049667757004499435,\n",
       " -0.018358178436756134,\n",
       " -0.026338055729866028,\n",
       " -0.0018965668277814984,\n",
       " -0.030247211456298828,\n",
       " -0.033148739486932755,\n",
       " -0.020293060690164566,\n",
       " -0.009031693451106548,\n",
       " 0.0077094887383282185,\n",
       " -0.04455159232020378,\n",
       " -0.018661534413695335,\n",
       " -0.06511973589658737,\n",
       " -0.012562129646539688,\n",
       " -0.008751587010920048,\n",
       " -0.026399264112114906,\n",
       " -0.03930191695690155,\n",
       " 0.012985159642994404,\n",
       " 0.0009903867030516267,\n",
       " -0.05257682874798775,\n",
       " -0.043698690831661224,\n",
       " -0.0014792496804147959,\n",
       " -0.020519759505987167,\n",
       " -0.02833809144794941,\n",
       " -0.033872783184051514,\n",
       " 0.001073150779120624,\n",
       " 0.0018260865472257137,\n",
       " 0.03670642524957657,\n",
       " 0.019265394657850266,\n",
       " -0.004383743740618229,\n",
       " -0.04091346263885498,\n",
       " 0.011824040673673153,\n",
       " -0.005792177747935057,\n",
       " -0.005758779123425484,\n",
       " 0.0005767454276792705,\n",
       " -0.055056601762771606,\n",
       " -0.03870627284049988,\n",
       " -0.020626628771424294,\n",
       " -0.01323393452912569,\n",
       " 0.039537739008665085,\n",
       " -0.057791195809841156,\n",
       " -0.007754965219646692,\n",
       " 0.024173561483621597,\n",
       " 0.02507415972650051,\n",
       " 0.02731885202229023,\n",
       " 0.05695023015141487,\n",
       " 0.016040770336985588,\n",
       " -0.0026411302387714386,\n",
       " 0.04965323209762573,\n",
       " 0.008356762118637562,\n",
       " 0.061596665531396866,\n",
       " 0.05627791956067085,\n",
       " -0.08359462022781372,\n",
       " 0.02635508030653,\n",
       " -0.010698596946895123,\n",
       " 0.02440774254500866,\n",
       " 0.01407166849821806,\n",
       " -0.027566032484173775,\n",
       " -0.023745408281683922,\n",
       " 0.027218090370297432,\n",
       " 0.013740110211074352,\n",
       " 0.023683931678533554,\n",
       " -0.018667778000235558,\n",
       " -0.02081146463751793,\n",
       " 0.020935077220201492,\n",
       " -0.036608655005693436,\n",
       " -0.023289958015084267,\n",
       " 0.036158788949251175,\n",
       " -0.010336661711335182,\n",
       " -0.014135521836578846,\n",
       " -0.01569400355219841,\n",
       " 0.00252005853690207,\n",
       " 0.060007933527231216,\n",
       " -0.01889587938785553,\n",
       " -0.00369451055303216,\n",
       " 0.01667884923517704,\n",
       " -0.021583015099167824,\n",
       " -0.02031807415187359,\n",
       " -0.011504587717354298,\n",
       " -0.005817567929625511,\n",
       " 0.02735385298728943,\n",
       " -0.02015710063278675,\n",
       " 0.037072423845529556,\n",
       " 0.012350409291684628,\n",
       " -0.05030307546257973,\n",
       " 0.026115968823432922,\n",
       " -0.0213908813893795,\n",
       " -0.04742912948131561,\n",
       " -0.016502700746059418,\n",
       " -0.0013431021943688393,\n",
       " 0.022205427289009094,\n",
       " 0.0494261160492897,\n",
       " -0.03363567218184471,\n",
       " 0.029423099011182785,\n",
       " -0.008891737088561058,\n",
       " -0.001592301414348185,\n",
       " -0.05596436187624931,\n",
       " 0.016033757477998734,\n",
       " -0.08601681143045425,\n",
       " -0.042839016765356064,\n",
       " 0.004859818145632744,\n",
       " -0.02492070011794567,\n",
       " 0.01998557150363922,\n",
       " 0.030382148921489716,\n",
       " -0.03413720801472664,\n",
       " -0.0166985634714365,\n",
       " -0.03135130926966667,\n",
       " 0.04043436795473099,\n",
       " 0.007736633066087961,\n",
       " 0.01796635612845421,\n",
       " -0.05491786077618599,\n",
       " 0.030048655346035957,\n",
       " 0.041341304779052734,\n",
       " -0.04408247023820877,\n",
       " -0.009688143618404865,\n",
       " 0.028382224962115288,\n",
       " 0.023012293502688408,\n",
       " -0.039238885045051575,\n",
       " -0.021410930901765823,\n",
       " 0.03264927119016647,\n",
       " 0.044089000672101974,\n",
       " -0.04314485564827919,\n",
       " -0.09732064604759216,\n",
       " 0.006835732143372297,\n",
       " -0.01897713914513588,\n",
       " 0.04715490713715553,\n",
       " 0.09451233595609665,\n",
       " -0.008004832081496716,\n",
       " 0.016579311341047287,\n",
       " 0.013765614479780197,\n",
       " -0.005970584694296122,\n",
       " -0.006443103775382042,\n",
       " -0.02812177501618862,\n",
       " -0.001927143195644021,\n",
       " -0.02798275090754032,\n",
       " -0.014233880676329136,\n",
       " 0.08600840717554092,\n",
       " -0.015842122957110405,\n",
       " -0.06070134416222572,\n",
       " -0.03152429684996605,\n",
       " 0.014266560785472393,\n",
       " -0.026387721300125122,\n",
       " -0.01835273951292038,\n",
       " -0.03486102819442749,\n",
       " -0.012998278252780437,\n",
       " 0.008446572348475456,\n",
       " -0.06985459476709366,\n",
       " -0.05057017132639885,\n",
       " 0.027132486924529076,\n",
       " -0.015844563022255898,\n",
       " 0.0318075492978096,\n",
       " 0.017198968678712845,\n",
       " -0.0694240927696228,\n",
       " 0.006685903295874596,\n",
       " 0.053455453366041183,\n",
       " -0.02864377386868,\n",
       " -0.02810651995241642,\n",
       " 0.062384650111198425,\n",
       " 0.011768991127610207,\n",
       " 0.028688015416264534,\n",
       " -0.09442153573036194,\n",
       " -0.019701242446899414,\n",
       " 0.0423697829246521,\n",
       " -0.0925670638680458]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.embed_query(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a11bd",
   "metadata": {},
   "source": [
    "## Agenda of tommorow session\n",
    "\n",
    "1. Understand the use case in better way\n",
    "2. Perform all the required experiment in notebook\n",
    "3. Setup logging and exception\n",
    "4. config and utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96f618",
   "metadata": {},
   "source": [
    "### Next Week Onwards\n",
    "\n",
    "will start modular coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31710441",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70ee076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd13e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f69605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3b77da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\WORK\\\\LLM_learning_resources\\\\krish_naik_bootcamp\\\\lecture\\\\project_structure\\\\document_portal\\\\notebook'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e3412d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"data\", \"sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2953c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab066002",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "006248ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5d447be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is a experimental, there is no deterministic way to split the text\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ae13933",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f960f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\WORK\\\\LLM_learning_resources\\\\krish_naik_bootcamp\\\\lecture\\\\project_structure\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 0, 'page_label': '1'}, page_content='Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "535b0694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'd:\\\\WORK\\\\LLM_learning_resources\\\\krish_naik_bootcamp\\\\lecture\\\\project_structure\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7ed51ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67a40131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afb33dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_model.embed_documents(docs[0].page_content)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5580006",
   "metadata": {},
   "source": [
    "1. in memory(faiss is in memory vector store, chromadb)\n",
    "2. on disk storage(faiss, you can persist over the disk schema)\n",
    "3. cloud storage(cloud variant of faiss is not available)(pinecone, weaviate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3be15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "984062b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc = vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92ec8a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1dee8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever(search_kwargs={\"k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39329e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retriever.invoke(\"llama2 finetuning benchmark experiments.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e166ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "        Answer the question based on the context provide below.\n",
    "        if the context does not contain sufficient information, respond with:\n",
    "        \"I do not have enough information about this\"ArithmeticError\n",
    "        \n",
    "        Context: {context}\n",
    "        \n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "917cb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86ac3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "537a3909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n        Answer the question based on the context provide below.\\n        if the context does not contain sufficient information, respond with:\\n        \"I do not have enough information about this\"ArithmeticError\\n        \\n        Context: {context}\\n        \\n        Question: {question}\\n\\n        Answer:')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1e1086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfbae2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bfa89703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86495bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model \n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c7c7b6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, let me try to figure out how to answer the question about the Llama 2 fine-tuning benchmark experiments based on the provided context.\\n\\nFirst, I need to understand what the user is asking. They want information about the fine-tuning benchmark experiments related to Llama 2. The context provided includes several tables and some textual information. Let me scan through the context to find relevant sections.\\n\\nLooking at the tables, there\\'s a section labeled \"Fine-tuned\" under the Llama 2 entries. There are numbers associated with different model sizes (7B, 13B, 34B, 70B) and some other models like ChatGPT, MPT-instruct, Falcon-instruct. The numbers might represent performance metrics on various benchmarks. \\n\\nIn the text, there\\'s a mention of \"ablation experiments to demonstrate their importance\" and details about hyperparameters used during training, such as the AdamW optimizer, learning rate schedule, weight decay, etc. However, this seems more related to the pretraining process. \\n\\nThe \"Fine-tuned\" sections in the tables have entries for models like ChatGPT, MPT-instruct, Falcon-instruct, and Llama 2-Chat. For example, under Llama 2-Chat, there are percentages like 57.04, 60.59, 96.45 for different model sizes. The text also mentions that for the MMLU evaluation, details are in Table 19 and standard benchmarks in Table 20, but those tables aren\\'t provided here. \\n\\nThe context also includes some information about training improvements, like data cleaning, updated data mixes, increased tokens, longer context, and GQA for scalability. However, these are part of the pretraining phase. \\n\\nThe user is specifically asking about fine-tuning benchmarks. The relevant part seems to be the \"Fine-tuned\" rows in the tables. For example, under the \"Fine-tuned\" section, there\\'s a line for Llama 2-Chat with 7B, 13B models and their respective percentages. Also, other models like ChatGPT have entries here. \\n\\nBut the problem is that the tables are a bit disorganized and not clearly labeled. For instance, there\\'s a line that says \"Llama 2 7B 0.28 0.25 ...\" followed by numbers, but without clear column headers. It\\'s possible that these numbers represent performance metrics on specific benchmarks, but without knowing what each column corresponds to, it\\'s hard to interpret. \\n\\nAdditionally, there\\'s a mention of \"small delta (-0.9) between the \\'clean\\' subset performance and the sampling mean\" which might relate to some evaluation metrics, but it\\'s not clearly connected to the fine-tuning experiments. \\n\\nSince the user is asking for information on the fine-tuning benchmark experiments, I should look for any explicit discussion of fine-tuning in the text. However, the text provided doesn\\'t have a dedicated section explaining the fine-tuning process or the specific benchmarks used. The tables under \"Fine-tuned\" might be the closest thing, but without headers or explanations, their meaning is unclear. \\n\\nThe context also references other sections (like Section 4.1 for safety benchmarks, Section A.2.2 for individual benchmarks) which are not included here. Therefore, the available information might not be sufficient to answer the question in detail. \\n\\nGiven that the tables are not well-structured and there\\'s no explanatory text about the fine-tuning experiments, their setup, or the benchmarks used, I might not have enough information to provide a coherent answer. The user could be looking for details like which benchmarks were used, how the models performed, hyperparameters of the fine-tuning, etc., but the context doesn\\'t provide this. \\n\\nTherefore, I should conclude that the context doesn\\'t contain enough information to answer the question adequately.\\n</think>\\n\\nI do not have enough information about this.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"tell me about the llama2 finetuning benchmark experiments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7443fbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
